
#Connecting_google_drive_to_google_colab_notebook

!pip install -U -q PyDrive
from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive
from google.colab import auth
from oauth2client.client import GoogleCredentials

auth.authenticate_user()
gauth = GoogleAuth()
gauth.credentials = GoogleCredentials.get_application_default()
drive = GoogleDrive(gauth)

fileDownloaded = drive.CreateFile({'id':'your_id'})

from google.colab import drive
drive.mount('/content/drive')

#Importing_modules
import os
import json
import time
import shutil
import random
import pathlib
import warnings
import numpy as np
import pandas as pd
import tensorflow as tf
from tqdm import tqdm
from PIL import Image
from matplotlib import pyplot as plt
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.models import Model, Sequential
from tensorflow.keras.layers import (BatchNormalization, Dense, Dropout, GlobalAveragePooling2D,
                                     Input, InputLayer, Lambda, concatenate)
from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img
from tensorflow.keras.utils import plot_model, to_categorical

#Defining_path_to_images
train_dir = 'path'
val_dir = 'path'
test_dir = 'path'

#Preparing_batch_of_images
img_width = 224
img_height = 224

data_generator = ImageDataGenerator(
    rescale = 1. / 255)

train_set = data_generator.flow_from_directory(
    train_dir,
    target_size =(img_width, img_height),
    batch_size = 32,
    shuffle = True,
    class_mode = 'binary_or_categorical')

validation_set = data_generator.flow_from_directory(
    val_dir,
    target_size =(img_width, img_height),
    batch_size = 32,
    shuffle = True,
    class_mode = 'binary_or_categorical')

test_set = data_generator.flow_from_directory(
    test_dir,
    target_size =(img_width, img_height),
    batch_size = 32,
    shuffle = True,
    class_mode = 'binary_or_categorical')

#Appending_image_data_to_list_of_numpy_array
import tqdm
import math

train_set.reset()

x_train = np.array([])
y_train = np.array([])

for i in tqdm.tqdm(range(math.ceil(train_set.n / train_set.batch_size))):
    img, label = next(train_set)
    if i == 0:  
        x_train = img
        y_train = label
    else:  
        x_train = np.append(x_train, img, axis=0 )
        y_train = np.append(y_train, label, axis=0)

validation_set.reset()

x_val = np.array([])
y_val = np.array([])

for i in tqdm.tqdm(range(math.ceil(validation_set.n / validation_set.batch_size))):
    img, label = next(validation_set)
    if i == 0:  
        x_val = img
        y_val = label
    else:  
        x_val = np.append(x_val, img, axis=0 )
        y_val = np.append(y_val, label, axis=0)

test_set.reset()

x_test = np.array([])
y_test = np.array([])

for i in tqdm.tqdm(range(math.ceil(test_set.n / test_set.batch_size))):
    img, label = next(test_set)
    if i == 0:  
        x_test = img
        y_test = label
    else:  
        x_test = np.append(x_test, img, axis=0 )
        y_test = np.append(y_test, label, axis=0)

#Training_AutoKeras
!pip install autokeras
import autokeras as ak

clf = ak.ImageClassifier(overwrite=True, max_trials=50, seed = 0, )
clf.fit(
    x_train, y_train,
    batch_size = 32,
    epochs = 100,
    validation_data = (x_val, y_val),

)

#Exporting_AutoKeras_model
model = clf.export_model()
model.save("model_name.hdf5")

#Transfer_learning
from keras.callbacks import EarlyStopping, ModelCheckpoint
early_stopping = EarlyStopping(monitor='val_loss', patience=20, verbose=1, restore_best_weights=True)

filepath = 'hsv_VGG19_2_class_GAE_adam.hdf5'
model_checkpoint = ModelCheckpoint(filepath, verbose=1, save_best_only=True)

from tensorflow.keras.applications import 'Name_of_model_you_want_to_load_from_keras'

base_model = 'Name_of_model_you_want_to_load_from_keras'(weights='imagenet', include_top=False)
base_model.trainable = False

x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dense(1024, activation='relu')(x)

predictions = Dense('number_of_classes', activation = 'sigmoid_or_softmax')(x)

model = Model(inputs=base_model.input, outputs=predictions)

for layer in base_model.layers:
    layer.trainable = False

from keras.optimizers import Adam
opt = Adam(learning_rate=0.001)

model.compile(optimizer= opt,
                  loss = keras.losses.'loss_function'(from_logits=False), metrics = [keras.metrics.'loss_function'()])

tf.random.set_seed(42)
history = model.fit(train_set,
          validation_data=(validation_set),
          epochs=100,
          callbacks=[early_stopping, model_checkpoint])

